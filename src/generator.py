#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è™šæ‹Ÿå¥³å‹æ•°æ®é›†ç”Ÿæˆå™¨
è´Ÿè´£ä»åœºæ™¯ç›®å½•ç”Ÿæˆè®­ç»ƒæ•°æ®é›†
"""

import json
import random
from datetime import datetime
from typing import List, Dict, Any
from scenarios import SCENARIO_CATALOG, validate_catalog, get_catalog_metadata


class GirlfriendDatasetGenerator:
    """è™šæ‹Ÿå¥³å‹æ•°æ®é›†ç”Ÿæˆå™¨ç±»"""
    
    def __init__(self, scenarios=None):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            scenarios: åœºæ™¯åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤çš„SCENARIO_CATALOG
        """
        self.scenarios = scenarios if scenarios is not None else SCENARIO_CATALOG
        validate_catalog()
        self.metadata = get_catalog_metadata()
    
    def generate_single_entry(self, scenario, variation_index: int = 0) -> Dict[str, str]:
        """
        ä»å•ä¸ªåœºæ™¯ç”Ÿæˆä¸€æ¡æ•°æ®
        
        Args:
            scenario: åœºæ™¯å¯¹è±¡
            variation_index: å˜ä½“ç´¢å¼•ï¼Œç”¨äºé€‰æ‹©ä¸åŒçš„å“åº”æ¨¡æ¿
        
        Returns:
            åŒ…å«instruction, input, outputçš„å­—å…¸
        """
        # å¾ªç¯é€‰æ‹©å“åº”æ¨¡æ¿
        response_template = scenario.response_templates[
            variation_index % len(scenario.response_templates)
        ]
        
        return {
            "instruction": scenario.instruction,
            "input": scenario.input,
            "output": response_template
        }
    
    def generate_deterministic_dataset(self, variations_per_scenario: int = 1) -> List[Dict[str, str]]:
        """
        ç¡®å®šæ€§åœ°ç”Ÿæˆæ•°æ®é›†ï¼ˆæ¯ä¸ªåœºæ™¯æŒ‰é¡ºåºç”Ÿæˆï¼‰
        
        Args:
            variations_per_scenario: æ¯ä¸ªåœºæ™¯ç”Ÿæˆçš„å˜ä½“æ•°é‡
        
        Returns:
            æ•°æ®é›†åˆ—è¡¨
        """
        dataset = []
        
        # æŒ‰é¡ºåºéå†æ‰€æœ‰åœºæ™¯
        for scenario in self.scenarios:
            # ä¸ºæ¯ä¸ªåœºæ™¯ç”ŸæˆæŒ‡å®šæ•°é‡çš„å˜ä½“
            for i in range(variations_per_scenario):
                entry = self.generate_single_entry(scenario, i)
                dataset.append(entry)
        
        return dataset
    
    def generate_random_dataset(self, num_samples: int = 500, seed: int = None) -> List[Dict[str, str]]:
        """
        éšæœºç”Ÿæˆæ•°æ®é›†ï¼ˆæ—§ç‰ˆå…¼å®¹æ¨¡å¼ï¼‰
        
        Args:
            num_samples: è¦ç”Ÿæˆçš„æ ·æœ¬æ•°é‡
            seed: éšæœºç§å­ï¼Œç”¨äºå¤ç°
        
        Returns:
            æ•°æ®é›†åˆ—è¡¨
        """
        if seed is not None:
            random.seed(seed)
        
        dataset = []
        
        for _ in range(num_samples):
            # éšæœºé€‰æ‹©ä¸€ä¸ªåœºæ™¯
            scenario = random.choice(self.scenarios)
            # éšæœºé€‰æ‹©ä¸€ä¸ªå“åº”æ¨¡æ¿
            response = random.choice(scenario.response_templates)
            
            entry = {
                "instruction": scenario.instruction,
                "input": scenario.input,
                "output": response
            }
            dataset.append(entry)
        
        return dataset
    
    def generate_balanced_dataset(self, samples_per_scenario: int = 10) -> List[Dict[str, str]]:
        """
        ç”Ÿæˆå¹³è¡¡çš„æ•°æ®é›†ï¼ˆæ¯ä¸ªåœºæ™¯ç”Ÿæˆç›¸åŒæ•°é‡çš„æ ·æœ¬ï¼‰
        
        Args:
            samples_per_scenario: æ¯ä¸ªåœºæ™¯ç”Ÿæˆçš„æ ·æœ¬æ•°é‡
        
        Returns:
            æ•°æ®é›†åˆ—è¡¨
        """
        dataset = []
        
        for scenario in self.scenarios:
            for _ in range(samples_per_scenario):
                # éšæœºé€‰æ‹©ä¸€ä¸ªå“åº”æ¨¡æ¿
                response = random.choice(scenario.response_templates)
                
                entry = {
                    "instruction": scenario.instruction,
                    "input": scenario.input,
                    "output": response
                }
                dataset.append(entry)
        
        # æ‰“ä¹±æ•°æ®é›†
        random.shuffle(dataset)
        
        return dataset
    
    def generate_dataset_with_metadata(
        self,
        num_samples: int = 500,
        mode: str = "random",
        **kwargs
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå¸¦å…ƒæ•°æ®çš„æ•°æ®é›†
        
        Args:
            num_samples: æ ·æœ¬æ•°é‡ï¼ˆä»…åœ¨randomæ¨¡å¼ä¸‹ä½¿ç”¨ï¼‰
            mode: ç”Ÿæˆæ¨¡å¼ï¼Œå¯é€‰ "random", "deterministic", "balanced"
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            åŒ…å«æ•°æ®é›†å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        if mode == "deterministic":
            variations_per_scenario = kwargs.get("variations_per_scenario", 1)
            dataset = self.generate_deterministic_dataset(variations_per_scenario)
        elif mode == "balanced":
            samples_per_scenario = kwargs.get("samples_per_scenario", 10)
            dataset = self.generate_balanced_dataset(samples_per_scenario)
        else:  # random
            seed = kwargs.get("seed", None)
            dataset = self.generate_random_dataset(num_samples, seed)
        
        return {
            "data": dataset,
            "metadata": {
                "total_samples": len(dataset),
                "total_scenarios": len(self.scenarios),
                "mode": mode,
                "generation_time": datetime.now().isoformat(),
                **kwargs
            }
        }
    
    def save_dataset(
        self,
        dataset: List[Dict[str, str]],
        output_path: str = None,
        include_metadata: bool = False
    ) -> str:
        """
        ä¿å­˜æ•°æ®é›†åˆ°JSONæ–‡ä»¶
        
        Args:
            dataset: æ•°æ®é›†åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            include_metadata: æ˜¯å¦åœ¨æ–‡ä»¶ä¸­åŒ…å«å…ƒæ•°æ®
        
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        import os
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "train_data/dataset"
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"{output_dir}/girlfriend_chat_dataset_{timestamp}.json"
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        if include_metadata:
            save_data = {
                "dataset": dataset,
                "metadata": self.metadata
            }
        else:
            save_data = dataset
        
        # ä¿å­˜ä¸ºJSONæ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
        
        return output_path
    
    def get_statistics(self, dataset: List[Dict[str, str]]) -> Dict[str, Any]:
        """
        è·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            dataset: æ•°æ®é›†åˆ—è¡¨
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        # ç»Ÿè®¡å„ä¸ªæŒ‡ä»¤çš„å‡ºç°æ¬¡æ•°
        instruction_counts = {}
        for entry in dataset:
            instruction = entry["instruction"]
            instruction_counts[instruction] = instruction_counts.get(instruction, 0) + 1
        
        # ç»Ÿè®¡emojiè¦†ç›–ç‡
        emoji_count = sum(1 for entry in dataset if any(
            char for char in entry["output"] 
            if ord(char) > 0x1F000
        ))
        
        # ç»Ÿè®¡è¾“å…¥ä¸ºç©ºçš„æ¯”ä¾‹
        empty_input_count = sum(1 for entry in dataset if not entry["input"])
        
        return {
            "total_samples": len(dataset),
            "unique_instructions": len(instruction_counts),
            "instruction_distribution": instruction_counts,
            "emoji_coverage": f"{emoji_count / len(dataset) * 100:.2f}%",
            "empty_input_ratio": f"{empty_input_count / len(dataset) * 100:.2f}%",
            "avg_output_length": sum(len(entry["output"]) for entry in dataset) / len(dataset)
        }
    
    def print_sample_data(self, dataset: List[Dict[str, str]], num_samples: int = 3):
        """
        æ‰“å°ç¤ºä¾‹æ•°æ®
        
        Args:
            dataset: æ•°æ®é›†åˆ—è¡¨
            num_samples: è¦æ‰“å°çš„æ ·æœ¬æ•°é‡
        """
        print(f"\nç¤ºä¾‹æ•°æ®:")
        for i in range(min(num_samples, len(dataset))):
            print(f"\n--- æ ·æœ¬ {i+1} ---")
            print(f"Instruction: {dataset[i]['instruction']}")
            print(f"Input: {dataset[i]['input']}")
            print(f"Output: {dataset[i]['output']}")


def generate_dataset(num_samples: int = 500) -> List[Dict[str, str]]:
    """
    ç”Ÿæˆæ•°æ®é›†çš„å¿«æ·å‡½æ•°ï¼ˆå‘åå…¼å®¹ï¼‰
    
    Args:
        num_samples: è¦ç”Ÿæˆçš„æ ·æœ¬æ•°é‡
    
    Returns:
        æ•°æ®é›†åˆ—è¡¨
    """
    generator = GirlfriendDatasetGenerator()
    return generator.generate_random_dataset(num_samples)


if __name__ == "__main__":
    # æµ‹è¯•ç”Ÿæˆå™¨
    print("æµ‹è¯•è™šæ‹Ÿå¥³å‹æ•°æ®é›†ç”Ÿæˆå™¨\n")
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = GirlfriendDatasetGenerator()
    
    # æ˜¾ç¤ºåœºæ™¯ç›®å½•ä¿¡æ¯
    print(f"ğŸ“Š åœºæ™¯ç›®å½•ä¿¡æ¯:")
    print(f"   æ€»åœºæ™¯æ•°: {generator.metadata['total_scenarios']}")
    print(f"   åˆ†ç±»æ•°: {len(generator.metadata['categories'])}")
    print(f"   åˆ†ç±»åˆ—è¡¨: {', '.join(generator.metadata['categories'])}")
    
    # æµ‹è¯•ç¡®å®šæ€§ç”Ÿæˆï¼ˆæ¯ä¸ªåœºæ™¯ç”Ÿæˆä¸€æ¬¡ï¼‰
    print(f"\nğŸ” æµ‹è¯•ç¡®å®šæ€§ç”Ÿæˆæ¨¡å¼...")
    deterministic_dataset = generator.generate_deterministic_dataset(variations_per_scenario=1)
    print(f"   ç”Ÿæˆæ ·æœ¬æ•°: {len(deterministic_dataset)}")
    print(f"   åº”ç­‰äºåœºæ™¯æ•°: {len(SCENARIO_CATALOG)}")
    assert len(deterministic_dataset) == len(SCENARIO_CATALOG), "ç¡®å®šæ€§ç”Ÿæˆå¤±è´¥"
    
    # éªŒè¯æ¯ä¸ªåœºæ™¯çš„æŒ‡ä»¤éƒ½æ˜¯å”¯ä¸€çš„
    instructions = [entry["instruction"] for entry in deterministic_dataset]
    assert len(instructions) == len(set(instructions)), "æŒ‡ä»¤å­˜åœ¨é‡å¤"
    print(f"   âœ… ç¡®å®šæ€§ç”ŸæˆéªŒè¯é€šè¿‡")
    
    # æ˜¾ç¤ºå‰3ä¸ªæ ·æœ¬
    generator.print_sample_data(deterministic_dataset, 3)
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = generator.get_statistics(deterministic_dataset)
    print(f"\nğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:")
    print(f"   æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
    print(f"   å”¯ä¸€æŒ‡ä»¤æ•°: {stats['unique_instructions']}")
    print(f"   Emojiè¦†ç›–ç‡: {stats['emoji_coverage']}")
    print(f"   ç©ºè¾“å…¥æ¯”ä¾‹: {stats['empty_input_ratio']}")
    print(f"   å¹³å‡è¾“å‡ºé•¿åº¦: {stats['avg_output_length']:.1f}å­—ç¬¦")
